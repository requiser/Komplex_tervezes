{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Bevezetés #",
   "id": "d343ea071aa2bf43"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "A szakdolgozatom célja, hogy a klasszikus idősor-elemzési módszereket ötvözve a modern természetes nyelvfeldolgozás (NLP) eszköztárával, új megközelítést kínáljak a részvényárfolyamok előrejelzésére. A részvénypiacok mozgásának előrejelzése mindig is kihívást jelentett, mivel azok volatilitását számos tényező befolyásolja, legyen szó makrogazdasági eseményekről, vállalati hírekről vagy akár a befektetők érzelmeiről. Az elmúlt években a mesterséges intelligencia, különösen az NLP fejlődése új kapukat nyitott meg a pénzügyi adatelemzésben, lehetővé téve a piacot befolyásoló hírek és szöveges tartalmak automatizált feldolgozását és értelmezését.\n",
    "\n",
    "A részvényárak előrejelzésére hagyományosan alkalmazott technikai elemzés számszerű múltbeli adatokra épít. Ugyanakkor a kutatások rámutattak, hogy a kizárólag technikai elemzésre támaszkodó megközelítések nem mindig vezetnek kielégítő eredményekhez, különösen a befektetői érzelmek és a hírek hatásának figyelmen kívül hagyása miatt. A pénzügyi hírek szöveges tartalmának elemzése azonban értékes információkat nyújthat, amelyeket kiegészítve a numerikus adatokkal pontosabb előrejelzések érhetők el.\n",
    "\n",
    "A szakdolgozatom keretében különös figyelmet fordítok a BERT (Bidirectional Encoder Representations from Transformers) modell alapú NLP technikákra, amelyek lehetővé teszik a pénzügyi hírek és közlemények precíz elemzését. Az idősor-elemzés hagyományos statisztikai modelljeit pedig viszonyítási alapként használom a kísérleti eredmények kiértékeléséhez.\n",
    "\n",
    "Informatikusként hiszem, hogy a mesterséges intelligencia és az természetes nyelvfeldolgozás integrációja a pénzügyi elemzésbe nemcsak a befektetési döntések gyorsaságát és pontosságát javíthatja, hanem hozzájárulhat a piacok átláthatóságához is. Ezért választottam a részvényárfolyamok előrejelzését az NLP módszereinek segítségével szakdolgozatom témájának, hiszen ez egy olyan terület, amely az innováció és a technológiai fejlődés határmezsgyéjén helyezkedik el. Az elvégzett kutatás reményeim szerint új perspektívát nyújthat a pénzügyi elemzések világában, és hozzájárulhat a befektetési döntéshozatal hatékonyságának növeléséhez."
   ],
   "id": "2548311f459f3460"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Elméleti háttér",
   "id": "fc91b25d1c016e0d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Idősorok elemzésének alapjai\n",
    "\n",
    "Az idősor-elemzés az időben egymást követő adatok elemzésének tudománya, amelyet gyakran alkalmaznak a pénzügyben, gazdasági előrejelzések készítésében, meteorológiában és számos más tudományágban. Egy idősor elemzése során az a cél, hogy azonosítsuk a megfigyelt mintázatokat, megértjük azok struktúráját, és előrejelezzük a jövőbeli értékeket. Az idősorok megértéséhez elengedhetetlen a trendek, szezonális komponensek és véletlen zajok azonosítása és elemzése.\n"
   ],
   "id": "965d7bd1ad61d16a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Az idősorok jellemzői\n",
    "\n",
    "Az idősorok különböző összetevői az adatok dinamikus viselkedését tükrözik. Ezek megértése kulcsfontosságú a helyes modellalkotáshoz és előrejelzéshez.\n",
    "\n",
    "#### Trend ($T_t$)\n",
    "\n",
    "A trend az idősor hosszú távú irányultságát jelenti, amely lehet növekvő, csökkenő vagy stagnáló. Például egy GDP-alapú gazdasági előrejelzés lehet alapul tapasztalható növekedési trendre mutat.\n",
    "\n",
    "Matematikailag a trendet egyszerű lineáris formában is leírhatjuk:\n",
    "\n",
    "$$T_t = \\beta_0 + \\beta_1 t$$\n",
    "\n",
    "ahol $\\beta_0$ az idősor kezdeti értéke, $\\beta_1$ pedig a növekedés sebességét jelenti. Amennyiben a növekedés nem lineáris, polinomiális formát alkalmazhatunk:\n",
    "\n",
    "$$T_t = \\beta_0 + \\beta_1 t + \\beta_2 t^2$$\n",
    "\n",
    "A trendek azonosítása és modellezése kulcsfontosságú, mivel a véletlen idősor viselkedése gyakran rejt maga a rövid távú ingadozások mellett.\n",
    "\n",
    "#### Szezonalitás ($S_t$)\n",
    "\n",
    "A szezonalitás az adatok rendszeresen ismétlődő mintázatát jelenti, amelyet tipikusan az évszakok, hónapok vagy napok okoznak. Például a kiskereskedelmi forgalomban a decemberi hónap kiemelt értékeket mutat az ünnepi vásárlások miatt.\n",
    "\n",
    "A szezonalitás matematikai leírása gyakran trigonometrikus függvényekkel történik:\n",
    "\n",
    "$$S_t = A \\sin\\left(\\frac{2\\pi t}{P}\\right) + B \\cos\\left(\\frac{2\\pi t}{P}\\right)$$\n",
    "\n",
    "ahol $A$ és $B$ az amplitúdók, $P$ pedig a periódus. A szezonális hatások felismerése érdekében sokszor grafikus módszereket alkalmazunk, például a szezonális bontást, amely az idősor komponensekre bontását célozza.\n",
    "\n",
    "#### Ciklikusság ($C_t$)\n",
    "\n",
    "A ciklikus komponensek az idősorban hosszabb időközönként visszatérő mintázatokat jelentenek, amelyek nem feltétlenül szabályos időközönként ismétlődnek. A gazdasági ciklusok például ilyen ciklikus jelenségek.\n",
    "\n",
    "Egy ciklus azonosítása érdekében gyakran az autokorrelációs függvényt (ACF) használják. Az autokorrelációs függvény az idősor múltbeli értékeit és az aktuális értékeit közötti kapcsolatot vizsgálja, és segít az ismétlődő minták detektálásában.\n",
    "\n",
    "#### Véletlen zaj ($\\epsilon_t$)\n",
    "\n",
    "A véletlen zaj az idősor azon komponense, amely nem magyarázható a fent említett összetevők egyikével sem. Ez a rész véletlen fluktuációkat tartalmaz, amelyeket gyakran normális eloszlásúnak feltételezünk, az alábbi alakban:\n",
    "\n",
    "$$\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$$\n",
    "\n",
    "ahol $\\sigma^2$ a zaj varianciája. A véletlen zaj figyelembevétele különösen fontos a modellépítés során, mivel a tüzött zaj \"tüllesztett\" eredményekhez, ami rontja az előrejelzések pontosságát.\n"
   ],
   "id": "ab11b740e933165b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Idősorok stacionaritása\n",
    "\n",
    "A stacionaritás az idősor statisztikai tulajdonságainak állandóságát jelenti időben. Ez az elemzési feladat ellengedhetetlen az olyan klasszikus modellek alkalmazásához, mint az ARIMA.\n",
    "\n",
    "#### Matematikai definíció\n",
    "\n",
    "Egy idősor $\\{Y_t\\}$ stacioner, ha:\n",
    "* Az idősor várható értéke konstans: $\\mathbb{E}[Y_t] = \\mu$\n",
    "* Az idősor varianciája állandó: $\\text{Var}[Y_t] = \\sigma^2$\n",
    "* Az idősor autokorrelációja csak az időeltolódástól függ: $\\text{Cov}[Y_t, Y_{t-k}] = \\gamma(k)$.\n",
    "\n",
    "Ha az idősor nem stacioner, a modellezés előtt gyakran differenciálást alkalmazunk:\n",
    "\n",
    "$$\\Delta Y_t = Y_t - Y_{t-1}$$\n",
    "\n",
    "A differenciálás során a trend eltávolítható, és az idősor stacionáriussá tehető.\n",
    "\n",
    "#### Stacionaritás tesztelése\n",
    "\n",
    "Különböző statisztikai tesztek használatosak a stacionaritás ellenőrzésére:\n",
    "\n",
    "1. Augmented Dickey-Fuller (ADF) teszt: Ez a teszt a nullhipotézisként feltételezi, hogy az idősor nem stacioner. A p-érték alapján eldönthető, hogy elutasítjuk-e a hipotézist.\n",
    "2. Kwiatkowski-Phillips-Schmidt-Shin (KPSS) teszt: Ez a teszt a stacionaritást vizsgálja mint nullhipotézist, és ellenőrzést ad arra, hogy az idősor tartalmaz-e trendkomponenseket.\n"
   ],
   "id": "3d4f366433312dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Idősorok elemzésének modelljei\n",
    "\n",
    "#### Mozgóátlag modellek (MA)\n",
    "A mozgóátlag modellek a múltbeli hibák súlyozott átlagára alapján becsülik meg az idősor aktuális értékét. Egy $q$-rendű MA modell általános formája:\n",
    "\n",
    "$$Y_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q}$$\n",
    "\n",
    "ahol $\\mu$ az idősor átlaga, $\\theta_i$ pedig a múltbeli hibák súlyai.\n",
    "\n",
    "#### Autoregresszív modellek (AR)\n",
    "Az autoregresszív modellek az idősor jövőbeli értékét a múltbeli értékek lineáris kombinációjaként becsülik meg. Egy $p$-rendű AR($p$) modell matematikai formája a következőképpen írható fel:\n",
    "\n",
    "$$Y_t = \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + \\cdots + \\phi_p Y_{t-p} + \\epsilon_t$$\n",
    "\n",
    "ahol:\n",
    "* $Y_t$ az idősor aktuális értéke,\n",
    "* $\\phi_1, \\phi_2, \\ldots, \\phi_p$ a múltbeli értékek súlyai (autoregressziós paraméterek),\n",
    "* $\\epsilon_t$ a véletlen zaj, amely $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$ feltételezéssel írunk le.\n",
    "\n",
    "##### Az autoregresszív modellek tulajdonságai:\n",
    "1. Lineáris előrejelzés: Az AR($p$) modell a múltbeli értékek egyenes arányban befolyásolják a jövőt. A súlyok nagysága és előjele meghatározza, hogy az egyes múltbeli értékek mennyire erősen és milyen irányban hatnak az aktuális értékre.\n",
    "2. Rend ($p$) meghatározása: Az autoregresszív modell rendjét az adatok viselkedésének és az autokorrelációs függvény (ACF) elemzésével határozhatjuk meg. Az ACF megmutatja, hogy az idősor korábbi értékei hogyan függnek össze a korábbi értékekkel.\n",
    "3. Stacionaritási követelmény: Az AR($p$) modellek csak akkor működnek helyesen, ha az idősor stacioner. Az AR-paraméterek abszolútértékének összege egy adott feltétel szerint korlátozott:\n",
    "\n",
    "$$\\sum_{i=1}^p |\\phi_i| < 1$$\n",
    "\n",
    "##### Példa egy AR(1) modellre:\n",
    "Egy $p = 1$-rendű autoregresszív modell (AR(1)) a legegyszerűbb forma, amely a következőként írható fel:\n",
    "\n",
    "$$Y_t = \\phi_1 Y_{t-1} + \\epsilon_t$$\n",
    "\n",
    "Ebben az esetben az aktuális érték kizárólag az előző időpont értékétől függ. Ha $\\phi_1 > 0$, akkor a múltbeli értékek pozitívan korrelálnak az aktuális értékkel, míg $\\phi_1 < 0$ esetén a kapcsolat inverz.\n",
    "\n",
    "#### ARIMA modellek\n",
    "\n",
    "Az Autoregresszív Integrált Mozgóátlag (ARIMA) modellek az idősor elemzésének és előrejelzésének széles körben alkalmazott eszközei. Az ARIMA modellek az autoregressziót (AR), a differenciálást (I) és a mozgóátlagot (MA) kombinálják.\n",
    "\n",
    "##### Az ARIMA modell általános formája\n",
    "\n",
    "Az ARIMA modell matematikai egyenlete így írható fel:\n",
    "\n",
    "$$\\Phi_p(B)(1 - B)^dY_t = \\Theta_q(B)\\epsilon_t$$\n",
    "\n",
    "ahol:\n",
    "* $\\Phi_p(B) = 1 - \\phi_1 B - \\phi_2 B^2 - \\cdots - \\phi_p B^p$ az autoregresszív komponens,\n",
    "* $(1 - B)^d$ az integrálási (differenciálási) operátor a trend eltávolítására,\n",
    "* $\\Theta_q(B) = 1 + \\theta_1 B + \\theta_2 B^2 + \\cdots + \\theta_q B^q$ a mozgóátlag komponens,\n",
    "* $B$ az eltoló operátor, amelyet $Y_t = Y_{t-1}$ definícióval használunk.\n",
    "\n",
    "##### Paraméterek $(p, d, q)$ jelentése\n",
    "1. $p$ - autoregresszív (AR) komponens rendje: Az idősor aktuális értékét a múltbeli értékek száma alapján becsüli.\n",
    "2. $d$ - differenciálás mértéke: Az idősor stacionaritását biztosító differenciálások száma.\n",
    "3. $q$ - mozgóátlag (MA) komponens rendje: Az idősor aktuális értékét a múltbeli hibák alapján becsüli.\n",
    "\n",
    "##### Az ARIMA modellépítés lépései\n",
    "1. Adatok stacionaritásának vizsgálata: Augmented Dickey-Fuller (ADF) teszttel ellenőrizzük, hogy az idősor stacioner-e. Ha nem, differenciálást végzünk.\n",
    "2. Paraméterek meghatározása: Az ACF és a parciális autokorrelációs függvény (PACF) elemzésével meghatározzuk az optimális $p, d$ és $q$ értékeket.\n",
    "3. Modell illesztése: A kapott paraméterek alapján felépítjük az ARIMA modellt.\n",
    "4. Diagnosztikai vizsgálat: A modell maradékai (reziduálisokat) vizsgáljuk, hogy megfelelnek-e a fehér zaj tulajdonságainak.\n",
    "\n",
    "#### SARIMA modellek\n",
    "\n",
    "A SARIMA modellek az ARIMA kiterjesztett változatai, amelyek a szezonális mintázatokat is kezelik. Az általános modell neve: Szezonális Autoregresszív Integrált Mozgóátlag.\n",
    "\n",
    "##### SARIMA modell általános formája\n",
    "\n",
    "$$\\Phi_p(B)\\Phi_P(B^s)(1 - B)^d(1 - B^s)^DY_t = \\Theta_q(B)\\Theta_Q(B^s)\\epsilon_t$$\n",
    "\n",
    "ahol:\n",
    "* $\\Phi_P(B^s)$ és $\\Theta_Q(B^s)$ a szezonális AR és MA komponensek,\n",
    "* $D$ a szezonális differenciálás mértéke,\n",
    "* $s$ a szezonális periódus.\n",
    "\n",
    "A SARIMA modellek különösen alkalmasak az olyan idősorokra, amelyek egyaránt tartalmaznak trendeket és szezonális mintázatokat, például havi eladási adatokra.\n"
   ],
   "id": "eb1c82d67f251ef8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Természetes nyelvfeldolgozás (NLP)\n",
    "\n",
    "### NLP alapfogalmak és technikák\n",
    "A természetes nyelvfeldolgozás (Natural Language Processing, NLP) az a terület, amelynek célja az emberi nyelv számítógépes feldolgozása és megértése. Az NLP a mesterséges intelligencia feladatkörében helyezkedik el, és olyan feladatokat old meg, mint a szövegelemzés, gépi fordítás, nyelgenerálás és beszédfelismerés.\n",
    "\n",
    "#### Előfeldolgozási lépések\n",
    "Az NLP folyamatának első lépése az adat előkészítése, amely kulcsfontosságú a pontos elemzéshez és modellépítéshez. Az alábbi lépéseket tartalmazza:\n",
    "\n",
    "1. Tokenizálás:\n",
    "A szöveget kisebb egységekre, úgynevezett tokenekre bontjuk, amelyek lehetnek szavak, számok vagy egyéb jelek. Például: \"Ez\", \"egy\", \"példa\".\n",
    "A tokenizálás alapvető célja, hogy az elemzések számára strukturált adatokat biztosítson.\n",
    "\n",
    "2. Lemmatizálás és szótövezés:\n",
    "Ezek az eljárások a szavakat az alapformájukra redukálják. A lemmatizálás figyelembe veszi a szavak nyelvtani szerepét, míg a szótövezés (stemming) egyszerű egygyökű szabályokat használ.\n",
    "Például a \"futott\", \"futva\" és \"futás\" szavakat a \"fut\" alapformára hozza.\n",
    "\n",
    "3. Stop szavak eltávolítása:\n",
    "Az olyan gyakori szavak, mint \"a\", \"ez\", \"vagy\", \"is\", általában nem hordoznak értékes információt, így ezeket gyakran kiszűrik az elemzés során.\n",
    "\n",
    "4. Zajszűrés:\n",
    "A szövegből az irreleváns karakterek, jelek eltávolítják az elemzés során.\n",
    "\n",
    "#### Szövegreprezentációs módszerek\n",
    "\n",
    "Az NLP modelljei számára a nyelvi adatok számok formájában történő megjelenítése szükséges. Az alábbiakban néhány elterjed módszert ismertetünk:\n",
    "\n",
    "1. Bag of Words (BoW):\n",
    "A szöveget szavak halmazaként reprezentálja, ahol az egyes szavak előfordulásának gyakorisága rögzíti. Hátránya, hogy figyelmen kívül hagyja a szavak sorrendjét és kontextusát.\n",
    "\n",
    "2. Term Frequency-Inverse Document Frequency (TF-IDF):\n",
    "Ez a módszer a szavak relatív fontosságát méri egy dokumentumban, figyelembe véve, hogy egy adott szó milyen gyakran fordul elő az összes dokumentumban. A TF-IDF képlete:\n",
    "\n",
    "$$\\text{TF-IDF}(t, d, D) = \\text{TF}(t, d) \\times \\text{IDF}(t, D)$$\n",
    "\n",
    "ahol:\n",
    "* $\\text{TF}(t, d)$: a $t$ szó gyakorisága a $d$ dokumentumban,\n",
    "* $\\text{IDF}(t, D) = \\log \\frac{|D|}{1 + |\\{d \\in D : t \\in d\\}|}$: az inverz dokumentumfrekvencia.\n",
    "\n",
    "3. Word embeddings (Word2Vec, GloVe):\n",
    "Ezek a módszerek a szavak sűrű vektorreprezentációját állítják elő, amely figyelembe veszi a szavak kontextusát és hasonlóságát. A Word2Vec például a szavak n-dimenziós térben történő elhelyezésével nyeri ki a szavak vektori közötti kapcsolatokat.\n",
    "\n",
    "4. Kontextuális embeddings (BERT, GPT):\n",
    "Ezek az új generációs modellek nemcsak a szavak jelentését veszik figyelembe, hanem azok környezetét is. A BERT (Bidirectional Encoder Representations from Transformers) például pontosabb kontextusba ágyazott szóvektorokat biztosít.\n",
    "\n",
    "#### Szemantikai elemzés\n",
    "\n",
    "Az NLP-ben a szemantikai elemzés az emberi nyelv jelentésének feltárását célozza. Az alábbiakban a legfontosabb alkalmazásokat ismertetjük:\n",
    "\n",
    "1. Sentiment analízis:\n",
    "Ez a technika a szöveg érzelmi tónusának (pozitív, semleges, negatív) azonosítására irányul. Alkalmazása elterjed a közösségi médiaelemzésekben és a vásárlói visszajelzések feldolgozásában.\n",
    "\n",
    "2. Névelem-felismerés (NER):\n",
    "A szövegben szereplő entitások (személyek, helyek, dátumok) automatikus felismerése és osztályozása. Például egy \"Google\" entitást vállalatként azonosítja.\n",
    "\n",
    "3. Témamodellezés:\n",
    "Az LDA (Latent Dirichlet Allocation) segítségével a szövegből különböző témák automatikus kinyerése valósítható meg. Az LDA feltételezi, hogy a dokumentumok kevert témákat tartalmaznak, és minden téma adott szavak halmazát reprezentálja.\n",
    "\n",
    "### Modern NLP architektúrák\n",
    "#### Transformer architektúra\n",
    "A Transformer modell a természetes nyelvfeldolgozás forradalmiszemközének, amely figyfyelmi (self-attention) alapú. Az architektúra alapegyenlete:\n",
    "\n",
    "$$Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}}),V$$\n",
    "\n",
    "ahol:\n",
    "* Q: a lekérdezési mátrix (queries),\n",
    "* K: a kulcsok mátrixa (keys),\n",
    "* V: az értékek mátrixa (values),\n",
    "* $d_k$: a kulcsmátrix dimenziója.\n",
    "\n",
    "#### Előtanított nyelvi modellek\n",
    "A BERT (Bidirectional Encoder Representations from Transformers) az evolúziót, mint például a FinBERT - jelentős szerepet játszanak a pénzügyi szövegek feldolgozásában. A FinBERT + kifejezetten pénzügyi adatokra finomhangolható, így hatékonyabb szentiméntelemzésre és piacokkal kapcsolatos szövegek feldolgozására.\n"
   ],
   "id": "9e6184eb80b651e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Pénzügyi piacok elemzése\n",
    "### Piaci hatékonyság és előrejelezhetőség\n",
    "A pénzügyi piacok hatékonysága és előrejelezhetősége kulcsfontosságú kérdés a modern közgazdaságtanban és pénzügyi elemzésben. Az Efficient Market Hypothesis (EMH), vagyis a hatékony piacok elmélete, Eugene Fama nevéhez kötődik, aki 1970-ben alkotta meg az elmélet alapjait. Az elmélet szerint a piacok olyan hatékonyak, hogy minden releváns információ azonnal és teljes mértékben tükröződik az eszközök árában.\n",
    "\n",
    "#### Piaci hatékonyság típusai\n",
    "Az EMH három fő formát különböztet meg:\n",
    "\n",
    "1. Gyenge forma:\n",
    "   Ez azt állítja, hogy az árfolyamok csak a múltbeli adatokat és volumeneiket tükrözik. Ennek következménye, hogy a technikai elemzés nem nyújt előnyt az árba. Matematikailag szempontból a piaci árfolyamokat véletlenszerű (randomwalk) modellezzük:\n",
    "\n",
    "   $$P_t = P_{t-1} + \\epsilon_t$$\n",
    "\n",
    "   ahol:\n",
    "   * $P_t$: az árfolyam t időpontban,\n",
    "   * $\\epsilon_t$: független és azonos eloszlású véletlen zaj.\n",
    "\n",
    "2. Közepes forma:\n",
    "   Ez azt állítja, hogy az árfolyamok nemcsak a múltbeli adatokat, hanem az összes nyilvánosan elérhető információt is tartalmazzák. Ebben beletartoznak a vállalati jelentések, gazdasági hírek és politikai események. Ez az állítás megkérdőjelezi a fundamentális elemzés hatékonyságát.\n",
    "\n",
    "3. Erős forma:\n",
    "   Ez a forma állítja, hogy az árák minden információt tükröznek, beleértve a nyilvános és a bennfentes információkat is. Ha ez igaz lenne, senki sem tudna tartósan felülteljesíteni a piacot, még a bennfentes információk felhasználásával sem.\n",
    "\n",
    "#### Piaci anomáliák\n",
    "Bár az EMH széles körben elfogadott, számos kutatás mutatott ki anomáliákat, amelyek az elmélet gyengeségeire utalnak:\n",
    "\n",
    "* Hét napja hatás: Bizonyos napokon (például pénteken) az árfolyamok szisztematikusan eltérnek az átlagtól.\n",
    "* Január hatás: Az év első hónapjában gyakran magasabb hozamok figyelhetők meg.\n",
    "* Bennfentes kereskedelem: A bennfentes információk használata előnyt jelenthet, különösen az erős formájú piacok esetében.\n",
    "\n",
    "#### Piaci szentiméntés és viselkedési pénzügyek\n",
    "A piaci szentiméntés, vagyis a befektetők általános érzelmi állapota, jelentős hatással van az árfolyamokra. A viselkedési pénzügyek (behavioral finance) ezen hatásokat próbálja megérteni és modellezni.\n",
    "\n",
    "#### Befektetői hangulat mérése\n",
    "1. Közvetlen mérési módszerek:\n",
    "   A befektetők körében végzett felmérések és kérdőívek segítségével közvetlenül mérhetjük a piaci szentiméntet. Például az AAII Investor Sentiment Survey az amerikai befektetők optimizmusát és semlegességét méri.\n",
    "\n",
    "2. Közvetett indikátorok:\n",
    "   A piaci mutatók, például a VIX index (volatility index), a piaci kockázatvállalást és szentiméntet közvetett módon mérésére szolgálnak. Magas VIX-értékek jellemzően félelmet jeleznek a piacokon.\n",
    "\n",
    "3. Média alapú szentiméntés:\n",
    "   A hírek, közösségi média bejegyzések és pénzügyi elemzések automatikus szövegelemzése segítségével a piaci hangulat kvantitatív módon mérhető. Az NLP és szentiméntanalízis, például a FinBERT modell segítségével, fontos szerepet játszanak e folyamatban.\n",
    "\n",
    "#### Viselkedési torzítások\n",
    "A befektetők döntéseit gyakran irracionalitási tényezők befolyásolják, amelyek torzítják a piacok működését:\n",
    "\n",
    "1. Nyájhatás (herding effect):\n",
    "   A befektetők hajlamosak mások viselkedését követni, különösen bizonytalan környezetben. Ez jelentős árfolyam-ingadozást okozhat.\n",
    "\n",
    "2. Túlzott magabiztosság (overconfidence):\n",
    "   A befektetők túlbecsülik saját tudásukat és képességeiket, ami gyakran túlzott kockázatvállaláshoz vezet.\n",
    "\n",
    "3. Lehorgonyzás (anchoring):\n",
    "   Az árfolyamok elemzése során az emberek gyakran túl nagy jelentőséget tulajdonítanak egy korábbi értéknek vagy eseménynek, ami befolyásolja döntéseiket.\n"
   ],
   "id": "f03cc8ae52efaacd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hibrid modellezési megközelítések\n",
    "### Idősoros és szöveges adatok integrálása\n",
    "A különböző adatforrások egyesítése a pénzügyi modellezés új dimenzióját nyitja meg. Az idősorelemzés és az NLP együttes alkalmazása a strukturált (árfolyamok) és strukturálatlan (szövegek) adatok integrálására.\n",
    "\n",
    "#### Feature engineering\n",
    "Az adatokból kinyert jellemzők (features) alapvető szerepet játszanak az integrált modellek teljesítményében:\n",
    "\n",
    "1. Idősor jellemzők:\n",
    "   Az idősorokból statisztikai mutatókat nyerhetünk ki, mint például a mozgóátlagok, volatilitás, maximumok és minimumok.\n",
    "\n",
    "2. Szöveges jellemzők:\n",
    "   A szentiméntanalízis eredményeit, a TF-IDF értékeket vagy a szóbeágyazásokat kombinálhatjuk az idősorokkal. Például egy hír szentiméntjét és a hozzá kapcsolódó árfolyamváltozást egyaránt modellezhetjük.\n",
    "\n",
    "3. Jellemzők kombinálása:\n",
    "   Az idősor- és szöveges jellemzők egyesítése lehetővé teszi a komplex összefüggések feltárását.\n",
    "\n",
    "#### Modell architektúrák\n",
    "Az integrált adatelemzés különböző modellarchitektúrákat igényel:\n",
    "\n",
    "1. Párhuzamos feldolgozás:\n",
    "   Az idősor- és szöveges adatokat külön modellekben dolgozzák fel, majd az eredményeket kombinálják.\n",
    "\n",
    "2. Kaszkád modellek:\n",
    "   Az egyik modell eredményeit felhasználják egy másik modell számára.\n",
    "\n",
    "3. Ensemble módszerek:\n",
    "   Több modell eredményeinek kombinálásával növelhető az előrejelzések pontossága.\n",
    "\n",
    "### Mély tanulási alapú megoldások\n",
    "\n",
    "A mély tanulási (Deep Learning) módszerek az utóbbi években forradalmasították a pénzügyi előrejelzést és a természetes nyelvfeldolgozást. Az idősorok és szöveges adatok integrációjában különösen fontos szerepet játszanak az olyan modellek, amelyek képesek a komplex, nemlineáris kapcsolatok azonosítására.\n",
    "\n",
    "#### Rekurrens neurális hálózatok (RNN)\n",
    "\n",
    "Az RNN-ek alkalmasak az idősorok adatok modellezésére, mivel képesek kezelni a függőségeket képesek kezelni. Az alap RNN-ek azonban hosszú távú függőségekkel nem tudnak hatékonyan megbirkózni, ezért fejlesztették ki a következő speciális változatokat:\n",
    "\n",
    "1. LSTM (Long Short-Term Memory):\n",
    "   Az LSTM egységek képesek a hosszú távú függőségek kezelésére, mivel a memóriakap szabályozzák, hogy az információ hogyan áramlik a hálózaton keresztül:\n",
    "\n",
    "   $$f_t = \\sigma(W_f[h_{t-1}, x_t] + b_f),\\quad i_t = \\sigma(W_i[h_{t-1}, x_t] + b_i),$$\n",
    "\n",
    "   ahol:\n",
    "   * $f_t$: felejtési kapu,\n",
    "   * $i_t$: beviteli kapu,\n",
    "   * $\\sigma$: aktivációs függvény,\n",
    "   * $W$ és $b$: súlyok és bias paraméterek.\n",
    "\n",
    "2. GRU (Gated Recurrent Unit):\n",
    "   A GRU egy egyszerűbb alternatíva az LSTM-hez, amely kevesebb paramétert használ. Gyakrabban tanulást biztosít.\n",
    "\n",
    "#### Konvolúciós neurális hálózatok (CNN)\n",
    "\n",
    "A CNN-ek hagyományosan képfeldolgozásra lettek kifejlesztve, de időbeli mintázatok felismerésére is alkalmazhatók az idősor-elemzés során. A konvolúciós rétegek képesek a rövid távú mintázatok (például időben változások) azonosítására:\n",
    "\n",
    "$$z_{i,j} = \\sigma\\left(\\sum_{m,n} x_{i+m,j+n} \\cdot w_{m,n} + b\\right),$$\n",
    "\n",
    "ahol:\n",
    "* $x$: bementi adatok,\n",
    "* $w$: konvolúciós súlyok,\n",
    "* $b$: bias,\n",
    "* $\\sigma$: aktivációs függvény.\n",
    "\n",
    "#### Hibrid modellek\n",
    "\n",
    "A CNN és RNN kombinációja lehetővé teszi az idősorok és szöveges adatok egységes feldolgozását. A CNN-ek az időbeli mintázatokat, míg az LSTM vagy GRU az időbeli függőségeket azonosítják.\n",
    "\n",
    "1. CNN-LSTM:\n",
    "   A CNN-ek az idősorosadatok jellemzőinek kinyerésére, az LSTM pedig a hosszú távú kapcsolatok felismerésére használhatók. Ez különösen hasznos, ha az idősoradat-jellemzőket az árfolyam-előrejelzéshez kombinálják.\n",
    "\n",
    "2. Attention mechanizmus:\n",
    "   Az attention mechanizmus lehetővé teszi a modell számára, hogy az adatok releváns részeire fókuszáljon. Ez különösen hasznos, ha egy szöveg bizonyos része vagy egy időbeli árfolyammérték nagyobb jelentőséggel bír:\n",
    "\n",
    "   $$Attention(Q,K,V) = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V,$$\n",
    "\n",
    "   ahol:\n",
    "   * Q: lekérdezés (query) mátrix,\n",
    "   * K: kulcs (key) mátrix,\n",
    "   * V: érték (value) mátrix,\n",
    "   * $d_k$: dimenzióméret.\n",
    "\n",
    "3. Transformer alapú megoldások:\n",
    "   A Transformer architektúra önmagában is használható az idősorok és szöveges adatok elemzésére. A self-attention mechanizmus révén hatékonyan dolgozza fel az adatokat, és képes a hosszú távú kapcsolatok azonosítására is.\n",
    "\n",
    "## Teljesítményértékelés és validáció\n",
    "\n",
    "### Előrejelzési metrikák\n",
    "A modellek értékelésére többféle mutató is alkalmazható, amelyek lehetővé teszik a pontosság és a gyakorlati használhatóság megítélését.\n",
    "\n",
    "#### Statisztikai metrikák\n",
    "\n",
    "1. Mean Absolute Error (MAE):\n",
    "   Az abszolút hibák átlaga, amely a modellek általános pontosságát méri:\n",
    "\n",
    "   $$MAE = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|,$$\n",
    "\n",
    "   ahol:\n",
    "   * $y_i$: valódi érték,\n",
    "   * $\\hat{y}_i$: előrejelzett érték.\n",
    "\n",
    "2. Root Mean Square Error (RMSE):\n",
    "   Az RMSE nagyobb súlyt ad a nagyobb hibáknak, ezért jobbán kiemeli a modell nagyobb tévedéseit.\n",
    "\n",
    "   $$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2}.$$\n",
    "\n",
    "3. Mean Absolute Percentage Error (MAPE):\n",
    "   Az előrejelzési hibák relatív arányát méri:\n",
    "\n",
    "   $$MAPE = \\frac{1}{n} \\sum_{i=1}^n \\left|\\frac{y_i - \\hat{y}_i}{y_i}\\right| \\cdot 100.$$\n",
    "\n",
    "#### Pénzügyi metrikák\n",
    "\n",
    "1. Sharpe-ráta:\n",
    "   A hozam és kockázat arányát méri:\n",
    "\n",
    "   $$S = \\frac{\\bar{R} - R_f}{\\sigma},$$\n",
    "\n",
    "   ahol:\n",
    "   * $\\bar{R}$: portfólió átlaghozama,\n",
    "   * $R_f$: kockázatmentes hozam,\n",
    "   * $\\sigma$: portfólió szórása.\n",
    "\n",
    "2. Maximum drawdown:\n",
    "   A legnagyobb csökkenés egy csúcsról egy mélypontra:\n",
    "\n",
    "   $$MDD = \\frac{\\text{Peak Value} - \\text{Trough Value}}{\\text{Peak Value}}.$$\n",
    "\n",
    "3. Profit és veszteség (P&L):\n",
    "   Az előrejelzések alapján végrehajtott stratégiák nyereségességét méri.\n",
    "\n",
    "#### Validációs stratégiák\n",
    "A model robusztusságának és megbízhatóságának tesztelése kritikus fontosságú:\n",
    "\n",
    "1. Időbeli keresztvalidáció:\n",
    "   Az idősorosadatok időbeli függősége miatt hagyományos keresztvalidáció nem használható.\n",
    "   Az időbeli keresztvalidáció lépései:\n",
    "   * A múltbeli adatokból tanul a modell.\n",
    "   * A jövőbeli adatokon teszteli magát.\n",
    "\n",
    "2. Backtesting:\n",
    "   A történeti szimulációk révén a modell előrejelzését valós pénzi adatok alapján tesztelik.\n",
    "   Fontos figyelembe venni a tranzakciós költségeket és a piaci körülményeket.\n"
   ],
   "id": "375b1171f19915fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fejlesztői Dokumentáció és Implementáció",
   "id": "197ba630aeb1df5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Python nyelv és eszközeinek áttekintése\n",
    "\n",
    "A Python az egyik legszélesebb körben használt programozási nyelv a mesterséges intelligencia, gépi tanulás, adatelemzés és pénzügyi modellezés területén. A nyelv egyszerű szintaxisa, széles körű könyvtárainak ökoszisztémája és interaktív eszközei miatt ideális választás a szakdolgozathoz kapcsolódó idősor-elemzés és természetes nyelvfeldolgozási (NLP) feladatokhoz.\n",
    "\n",
    "A Python erőssége az eszközök egyszerű integrációjában rejlik. Az idősor-elemzés és NLP kombinációja érdekében az adatok előkészítésétől kezdve a modellezésen át az értékelésig lehetőség van egyetlen keretrendszerben lehet dolgozni.\n",
    "\n",
    "1. Adatintegráció és előfeldolgozás:\n",
    "A Pandas és a NumPy használható az idősorok előkészítésére, míg a szöveges adatok tisztításához az NLTK alkalmazható.\n",
    "\n",
    "2. Modellezés:\n",
    "A Scikit-learn és a TensorFlow eszközei lehetővé teszik a klasszikus és mélytanulási modellek egyidejű fejlesztését.\n",
    "\n",
    "4. Validáció és értékelés:\n",
    "Az idősoros validációhoz a Scikit-learn, míg a pénzügyi metrikák kiszámításához a NumPy és Pandas eszközök használhatók."
   ],
   "id": "24e374f101c4eed0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Használt könyvtárak",
   "id": "fe2630c28a3743d1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ast\n",
    "\n",
    "Az ast modul a Python beépített könyvtára, amely az absztrakt szintaxisfák (AST) kezelését támogatja.\n"
   ],
   "id": "63721075e85a791c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:29:58.925661Z",
     "start_time": "2024-11-26T13:29:58.742627Z"
    }
   },
   "cell_type": "code",
   "source": "import ast",
   "id": "bf80e9cd5f169e47",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### numpy\n",
    "\n",
    "A NumPy a Python egyik legfontosabb könyvtára a numerikus számításokhoz. Széleskörű támogatást nyújt tömbműveletekhez, lineáris algebrához és statisztikai számításokhoz."
   ],
   "id": "562ca8e87dd63799"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:12.011714Z",
     "start_time": "2024-11-26T13:31:11.996809Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "af37f10124e4246a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### pandas\n",
    "\n",
    "A Pandas könyvtár adatok kezelésére és elemzésére szolgál. A DataFrame struktúrája ideális táblázatos adatok manipulációjára."
   ],
   "id": "5af17ec390b87de5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:15.340011Z",
     "start_time": "2024-11-26T13:31:15.201974Z"
    }
   },
   "cell_type": "code",
   "source": "import pandas as pd",
   "id": "6358d6e6f77a3dcf",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### transformers\n",
    "\n",
    "Transformers könyvtár\n",
    "\n",
    "A Hugging Face Transformers könyvtár a modern NLP-modellek, például a BERT vagy GPT alkalmazását teszi lehetővé.\n",
    "\n",
    "#### Modulok bemutatása:\n",
    "* AutoTokenizer: Szövegek tokenizálásához használható."
   ],
   "id": "b4f0fa4b1f0ba9ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:18.050525Z",
     "start_time": "2024-11-26T13:31:17.846886Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoTokenizer",
   "id": "a53cc55a1a8d260e",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* AutoModelForSequenceClassification: Előtanított modellek betöltése osztályozási feladatokhoz.",
   "id": "973bb7300a91c355"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:22.277808Z",
     "start_time": "2024-11-26T13:31:21.926163Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import AutoModelForSequenceClassification",
   "id": "a75b102e5f415127",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "* pipeline: Egyszerűsített interfész különböző NLP-feladatokhoz, például szentimentelemzéshez.",
   "id": "62b1be6f57327453"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:24.560926Z",
     "start_time": "2024-11-26T13:31:24.545362Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers import pipeline",
   "id": "b49e123f94a5b0b7",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### matplotlib és plotly",
   "id": "72e58b0a714712a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A Matplotlib az egyik legszélesebb körben használt adatvizualizációs könyvtár.",
   "id": "8baced74ac06c54b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:28.427870Z",
     "start_time": "2024-11-26T13:31:27.951502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "plt.style.use('ggplot')"
   ],
   "id": "a30793b03d8bb2af",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "A Plotly interaktív adatvizualizációs könyvtár.",
   "id": "fee03ee69a7dc565"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:32.153371Z",
     "start_time": "2024-11-26T13:31:31.963352Z"
    }
   },
   "cell_type": "code",
   "source": "import plotly.graph_objects as go",
   "id": "d6b68f2e049af3d7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### yfinance\n",
    "\n",
    "A yfinance könyvtár egyszerű és gyors hozzáférést biztosít a Yahoo Finance API-jához, ami elérhetővé teszi a tőzsdei adatok lekérdezését."
   ],
   "id": "c3cd5f8296d82a21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:35.634912Z",
     "start_time": "2024-11-26T13:31:34.834481Z"
    }
   },
   "cell_type": "code",
   "source": "import yfinance as yf",
   "id": "d9ae6eabcd3e41d6",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### backtrader\n",
    "\n",
    "A backtrader egy tőzsdei kereskedési stratégiák szimulálására alkalmas könyvtár."
   ],
   "id": "73093f659f2814b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:39.640168Z",
     "start_time": "2024-11-26T13:31:39.439723Z"
    }
   },
   "cell_type": "code",
   "source": "import backtrader as bt",
   "id": "29b3ae92f89e923b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### tqdm\n",
    "\n",
    "A tqdm egy egyszerű, de hatékony eszköz a Python programok futási állapotának vizualizálására."
   ],
   "id": "11637fe84f24b896"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-26T13:31:50.951965Z",
     "start_time": "2024-11-26T13:31:50.832253Z"
    }
   },
   "cell_type": "code",
   "source": "from tqdm.notebook import tqdm",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NLP modellek\n",
    "\n",
    "A Huggingface honlapján találkható előre betanított modellek lekérése és felhasználása egy transformers pipeline létrehozásához."
   ],
   "id": "32573c757fff0969"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DistilRoBERTa\n",
    "\n",
    "Ez a modell a RoBERTa-bázismodell desztillált változata a Financial PhraseBank adat gyűjteményén finomhangolva.\n",
    "A modell kis- és nagybetű-érzékeny, továbbá 6 réteggel, 768 dimenzióval és 12 fejjel rendelkezik, összesen 82M paraméterrel.\n",
    "\n",
    "https://huggingface.co/mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis"
   ],
   "id": "d662b446a895b334"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:32:10.809362Z",
     "start_time": "2024-11-26T13:32:07.994994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_DistRoBERTa = f\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\"\n",
    "\n",
    "\n",
    "_sentiment_analysis_DistRoBERTa = pipeline(\"sentiment-analysis\",\n",
    "                                           model= AutoModelForSequenceClassification.from_pretrained(\n",
    "                                               model_DistRoBERTa,\n",
    "                                               num_labels=3),\n",
    "                                           tokenizer=AutoTokenizer.from_pretrained(model_DistRoBERTa),\n",
    "                                           top_k=None, padding=True, truncation=True\n",
    "                                           )"
   ],
   "id": "6eb0240a229e1ea1",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### FinBERT\n",
    "\n",
    "A FinBERT egy előre betanított NLP modell (BERT nyelvi modell továbbképzése) pénzügyi szövegek hangulatának elemzésére.\n",
    "Ez a modell is a Financial PhraseBank adat gyűjteményen lett finomhangolva.\n",
    "\n",
    "https://huggingface.co/ProsusAI/finbert"
   ],
   "id": "8843e8e9d3793639"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:29:49.893224Z",
     "start_time": "2024-11-26T13:29:43.228949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_FinBERT = \"ProsusAI/finbert\"\n",
    "_sentiment_analysis_FinBERT = pipeline(\"sentiment-analysis\",\n",
    "                                       model=AutoModelForSequenceClassification.from_pretrained(\n",
    "                                           model_FinBERT,\n",
    "                                           num_labels=3\n",
    "                                       ),\n",
    "                                       tokenizer=AutoTokenizer.from_pretrained(model_FinBERT),\n",
    "                                       top_k=None, padding=True, truncation=True\n",
    "                                       )"
   ],
   "id": "f4270dc9c2d1ae63",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### DeBERTa\n",
    "\n",
    "A DeBERTa a BERT és a RoBERTa modelleket javítja a szétválasztott figyelem és a továbbfejlesztett maszkdekóder használatával.\n",
    "Ezzel a két fejlesztéssel a DeBERTa 80 GB képzési adatmennyiséggel az NLU-feladatok többségében felülmúlja a RoBERTa-t.\n",
    "\n",
    "https://huggingface.co/mrm8488/deberta-v3-ft-financial-news-sentiment-analysis"
   ],
   "id": "a9d3787517fa662b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T13:29:55.789384Z",
     "start_time": "2024-11-26T13:29:50.499069Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 12,
   "source": [
    "model_DeBERTa = f\"mrm8488/deberta-v3-ft-financial-news-sentiment-analysis\"\n",
    "_sentiment_analysis_DeBERTa = pipeline(\"sentiment-analysis\",\n",
    "                                       model=AutoModelForSequenceClassification.from_pretrained(\n",
    "                                           model_DeBERTa,\n",
    "                                           num_labels=3),\n",
    "                                       tokenizer=AutoTokenizer.from_pretrained(model_DeBERTa),\n",
    "                                       top_k=None, padding=True)"
   ],
   "id": "c8b888a477e13cf5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Használt adatok",
   "id": "dc53944c5b24e7da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Függvények",
   "id": "2323d64e179bdb54"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Összefoglalás",
   "id": "dac6b6d9538808e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summary",
   "id": "3a77e30edaa66de5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Irodalomjegyzék",
   "id": "ae989507d27b1954"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
